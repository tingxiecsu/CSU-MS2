batch_size: 1100
epochs: 2000
eval_every_n_epochs: 5
smilesmodel_finetune: False
smilesmodel_finetune_path: ".../"
fine_tune_from: ".../"
log_every_n_steps: 2
learning_rate: 1e-06
weight_decay: 0.0001
fp16_precision: True
truncation: True

model_config:
  num_layer: 5
  emb_dim: 300
  feat_dim: 512
  drop_ratio: 0.3
  pool : mean
  spec_embed_dim: 256
  dropout: 0.1
  layers: 3
  embed_dim: 256
  
dataset:
  s: 1
  num_workers: 0
  valid_size: 0.2
  ms2_file: ".../.mgf"
  smi_file: ".../.npy"

loss:
  temperature: 0.1
  use_cosine_similarity: True
  alpha_weight: 0.75
