batch_size: 1000
epochs: 5000
eval_every_n_epochs: 5
smilesmodel_finetune: False
smilesmodel_finetune_path: ""
fine_tune_from: "/"
log_every_n_steps: 2
learning_rate: 1e-05
weight_decay: 0.0001
fp16_precision: True
truncation: True

model_config:
  num_layer: 5
  emb_dim: 300
  feat_dim: 512
  drop_ratio: 0.3
  pool : mean
  spec_embed_dim: 256
  dropout: 0.1
  layers: 3
  embed_dim: 256
  
dataset:
  s: 1
  num_workers: 0
  valid_size: 0.1
  ms2_file: ""
  smi_file: ""

loss:
  temperature: 0.1
  use_cosine_similarity: True
  alpha_weight: 0.75
